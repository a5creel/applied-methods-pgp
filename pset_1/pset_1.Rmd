---
title: "Problem Set 1"
subtitle: "Applied Methods"
author: "Andie Creel"
date: "2023-01-25"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(vroom)
library(dplyr)
library(sandwich)
library(formatR)

```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=55), tidy=TRUE)
```

\newcommand{\indep}{\perp \!\!\! \perp}

## Question One: Randomization
This analysis will use the Dehijia and Wahba sample from the Lalonde dataset of the NSW experiment. The dataset is lalonde_nsw.csv. The outcome variable is re78 (real earnings in 1978). The treatment indicator is treat. The remaining variables are potential covariates. Assume for the purposes of this problem set that treat is completely randomly assigned.

### a. Calculate the average treatment effect of the policy $E(\tau_i)$ using a simple difference in means.

Under random assignment, we know that $\hat{\tau} = \sum_i \frac{Y_{i,1}}{D_i} - \sum_i \frac{Y_{i,0}}{1-D_i}$.

```{r, message=FALSE}
# --------------------------------------------------------------
# read in data 
# --------------------------------------------------------------
# myData <- vroom('https://raw.githubusercontent.com/paulgp/applied-methods-phd/main/homework/Homework1/lalonde_nsw.csv')
# vroom_write(myData, file = "lalonde_nsw.csv")

myData <- vroom('lalonde_nsw.csv')

# --------------------------------------------------------------
# calculating tau
# --------------------------------------------------------------
#calculating number of treated and control
calcATE <- function(df){
  D1 <- sum(df$treat)
  D0 <- sum(1-df$treat)
  
  # sum of outcome for treated 
  Y1_df <- df %>%
    filter(treat == 1) %>%
    select(re78)
  
  Y1 <- sum(Y1_df$re78) ; rm(Y1_df)
  
  # sum of outcome for control 
  Y0_df <- df %>%
    filter(treat == 0) %>%
    select(re78)
  
  Y0 <- sum(Y0_df$re78) ; rm(Y0_df)
  
  #calculating tau hat
  t_hat <- Y1/D1 - Y0/D0
  return(t_hat)
}

t_hat<-calcATE(myData)
```

I find that $\hat{\tau}$ is `r round(t_hat, 2)`.

### b. Calculate the average treatment effect on the treated of the policy $E(\tau_i | treat = 1)$. How does it compare to part a?

Because treatment is randomly assigned (and we assume there are no violators to their treatment status), $E[Y_i(0) | D_i = 0] = E[Y_i(0) | D_i = 1]$. Therefore the average treatment on the treated with be the same as the average treatment effect and the answer does not differ from part a. 

### c. Test the null of $\tau_i = 0$ for all i using a randomization test. *N.B.* Hold fixed the number of treated and control (e.g. assume the treatment count would be held fixed) and permute the labels randomly 1000 times – you do not need to fully do every permutation (there would be too many). Report the quantile that your estimate from the previous question falls.

```{r}
# ----------------------------------------------------------------------------
# functions
# ----------------------------------------------------------------------------

#calculate the average treatement effect for a sample
calc_ATE_samp <- function(df){

  #calculating number of treated and control
  D1 <- sum(df$treat_new)
  D0 <- sum(1-df$treat_new)
  
  # sum of outcome for treated 
  Y1_df <- df %>%
    filter(treat_new == 1) %>%
    select(re78)
  
  Y1 <- sum(Y1_df$re78) ; rm(Y1_df)
  
  # sum of outcome for control 
  Y0_df <- df %>%
    filter(treat_new == 0) %>%
    select(re78)
  
  Y0 <- sum(Y0_df$re78) ; rm(Y0_df)
  
  #calculating tau hat
  t_hat <- Y1/D1 - Y0/D0
  return(t_hat)
}

#get a sample ATE
get_sample_ate <- function(){
  # step one: randomize assignment of treatment and control
  mySample <- myData %>%
    mutate(treat_new = sample(treat, replace = FALSE))
 
  #step two: calculate t_hat 
  calc_ATE_samp(mySample)
}


# ----------------------------------------------------------------------------
# Create a distribution and find p value
# ----------------------------------------------------------------------------

#create a distribution
myDist <- replicate(1000, get_sample_ate())

#indicate if sample's tau is bigger than estimated tau
myDist_df <- data.frame(sample_tau = myDist) %>%
  mutate(perc = if_else(sample_tau>t_hat, 1,0))

#calc p value
pval <- sum(myDist_df$perc)/1000

```
I find that the p-value is `r pval`. 


### d. Run a regression using robust standard errors (you may use canned software) of the outcome on the treatment dummy, and compare the p-values from this test to the previous answer.

```{r}
myReg <- lm(data = myData, formula = re78 ~ treat)

#robust standard errors
myRobustSE <- sqrt(diag(vcovHC(myReg)))

#treatment effect
effect <- summary(myReg)$coefficients[2,1]

# p-value for null 0 avg treatment effect in reg.1, vs 2 sided alternative
round(2*(1-pnorm(abs(effect/myRobustSE[2]))),4)



```
I find a p-value that is less than .01, as does the canned regression. We can also see that the average treatment effects are equivalent. 


## Question Two: Propensity Scores
This analysis will use the dataset from Problem 1 as well as the PSID dataset from Dehijia and Wahba, lalonde-psid.csv. These datasets have identical variables. The new dataset is a sample of observations from the Panel Survey of Income Dynamics that can be used as alternative control observations. Importantly, these observations were not in the initial randomization.

### a. Using age, education, hispanic, black, married, nodegree, RE74 and RE75, construct a propensity score using the treated group in lalonde-nsw.csv and the control sample of lalonde-psid.csv. Use a logit regression model to do so (you may use a canned routine to run the regression). Report the average p-score for the treated and control samples, and plot the propensity score densities for the treatment and control groups.

Step one: create new data set with treated from nsw and control for psid 

Step two: calculate propensity scores using logit 

$\pi(\mathbf{X_i}) = Pr(D_i = 1 | \mathbf{X_i})$

Step three: Subset by treated and control, calculate average propensity score for two groups. If there was random assignment, you would expect these to be the same (?)


```{r, message=FALSE}
# mySample <- vroom("https://raw.githubusercontent.com/paulgp/applied-methods-phd/main/homework/Homework1/lalonde_psid.csv")
# vroom_write(mySample, "lalonde_psid.csv")

# ----------------------------------------------------------------------------
# read in data, make new data set
# ----------------------------------------------------------------------------
myData <- vroom("lalonde_nsw.csv") %>%
  filter(treat == 1)


mySample <- vroom("lalonde_psid.csv") %>%
  filter(treat == 0)

myData_2 <- bind_rows(myData, mySample) ; rm(myData, mySample)

myData_2 <- myData_2 %>% 
  select(treat, age, education, hispanic, black, married, nodegree, re74, re75, re78)
  

# ----------------------------------------------------------------------------
# calculate pscores 
# ----------------------------------------------------------------------------

#logit
myLogit <- glm(treat ~ age + education + hispanic + black +married + nodegree + re74 + re75, data = myData_2, family = "binomial")

# predict treatment given model (LOGIT RETURNS A LOG ODDS)
myData_2$log_odds <- predict(myLogit, newdata = myData_2)

# Transform to probability 
myData_2$odds <- exp(myData_2$log_odds)
myData_2$p_score <- myData_2$odds / (1+myData_2$odds)

# ----------------------------------------------------------------------------
# avg pscore for treated and control 
# ----------------------------------------------------------------------------

# treated
treat_df <- myData_2 %>%
  filter(treat == 1)

p_score_treat <- mean(treat_df$p_score) ; rm(treat_df)

# control 
control_df <- myData_2 %>%
  filter(treat == 0)

p_score_control<- mean(control_df$p_score) ; rm(control_df)

```

I get an average p-score the treatment of `r round(p_score_treat,2)` and `r round(p_score_control, 2)` for the control. 
	
### b. Using your p-score estimates, calculate the IPW and SIPW estimate for control and treated mean of the outcome, and the average treatment effect. Contrast these estimates to the control mean of the outcome from the NSW sample, and the treatment effect from last week’s problem set.

Assumptions: 
If we assume strong ignorability, $Y_i(0), Y_i(1) \indep D_i | \mathbf{X_i}$, then we know $(Y_i(0), Y_i(1) \indep D_i | \pi(\mathbf{X_i})$. This allows us to solve a high dimensional problem with a scalar value. 


**IPW**

Horvitz-Thompson estimator (aka inverse probability estimator): 

$$E[\tau_i] = E[\frac{Y_i D_i}{\pi(X_i) } - \frac{Y_i (1 - D_i)}{1 - \pi(X_i)}]$$

$$\hat{\tau_i} = \frac{1}{n} \sum_i \frac{Y_i D_i}{\pi_i} - \frac{Y_i (1 - D_i)}{1 - \pi_i} $$


```{r}
#outcome is re78

tau_hat_HC <- 1/length(myData_2$re78) * sum(myData_2$re78 * myData_2$treat/myData_2$p_score - myData_2$re78*(1 - myData_2$treat)/ (1 - myData_2$p_score))



```

I estimate the IPW is `r round(tau_hat_HC, 2)`.


**SIPW**

$$ \hat{\tau_{SIPW}} = \frac{n^{-1} \sum_i \frac{Y_i D_i}{\hat\pi_i}}{ n^{-1} \sum_i \frac{D_i}{\hat \pi_i}}  -  \frac{n^{-1} \sum_i \frac{Y_i (1-D_i))}{(1-\hat\pi_i)}}{ n^{-1} \sum_i \frac{1-D_i}{1-\hat \pi_i}}$$


```{r}
#t_hat_spiw = term_1/temp_2 - term_3/term_4

term_1 <- 1/length(myData_2$re78) * sum((myData_2$re78 * myData_2$treat)/myData_2$p_score)
term_2 <- 1/length(myData_2$re78) * sum(myData_2$treat/myData_2$p_score)


term_3 <-  1/length(myData_2$re78) * sum((myData_2$re78*(1 - myData_2$treat))/ (1 - myData_2$p_score))
term_4 <- 1/length(myData_2$re78) * sum((1-myData_2$treat)/(1-myData_2$p_score))

tau_hat_spiw <- term_1/term_2 - term_3/term_4 ; rm(term_1, term_2, term_3, term_4)


```
I estimate the SIPW is `r round(tau_hat_spiw, 2)`.


### c. Compare the ATE in the previous question to the treatment effect estimated using a linear regression using the PSID and NSW treatment sample, with age, education, hispanic, black, married, nodegree, RE74 and RE75 as controls.

```{r}
myReg_1 <- lm(data = myData_2, formula = re78 ~ treat+ age + education + hispanic + black + married + nodegree + re74 +re75)
summary(myReg_1)

```

I estimate an ATE of 751.95 when estimating using an OLS regression with controls. This is a very different treatment effect than the HC estimator and SIPW (which are very different from one another as well). 

### d. Now revisit your estimates from part a and b, and following Crump et al. (2009), discard all units with estimated propensities outside the range of [0.1, 0.9]. Reestimate the IPW and SIPW estimator of the ATE from part b using this trimmed sample.

```{r}
#trim
myData_3 <- myData_2 %>%
  filter(p_score < .9) %>%
  filter(p_score > .1)

#HC 
tau_hat_HC_trim <- 1/length(myData_3$re78) * sum(myData_3$re78 * myData_3$treat/myData_3$p_score - myData_3$re78*(1 - myData_3$treat)/ (1 - myData_3$p_score))

#SPIW
term_1 <- 1/length(myData_3$re78) * sum((myData_3$re78 * myData_3$treat)/myData_3$p_score)
term_2 <- 1/length(myData_3$re78) * sum(myData_3$treat/myData_3$p_score)

term_3 <-  1/length(myData_3$re78) * sum((myData_3$re78*(1 - myData_3$treat))/ (1 - myData_3$p_score))
term_4 <- 1/length(myData_3$re78) * sum((1-myData_3$treat)/(1-myData_3$p_score))

tau_hat_spiw_trim <- term_1/term_2 - term_3/term_4 ; rm(term_1, term_2, term_3, term_4)

```

I find that $\hat \tau_{HC_{trim}}$ is `r round(tau_hat_HC_trim,2)` and  $\hat \tau_{SPIW_{trim}}$ is `r round(tau_hat_spiw_trim,2)`. These are more similar to the treatment effect estimated by the regression. 

### d. Finally, calculate the IPW and SIPW estimates for the ATE using this trimmed sample for Black and non-Black individuals. Compare this estimate to the ATE for Black and non-Black individuals using the full randomized sample.

**IPW and SPIW for Black people**

```{r}
# Black 
myData_black <- myData_3 %>%
  filter(black == 1)

#HC 
tau_hat_HC_black <- 1/length(myData_black$re78) * sum(myData_black$re78 * myData_black$treat/myData_black$p_score - myData_black$re78*(1 - myData_black$treat)/ (1 - myData_black$p_score))

#SPIW
term_1 <- 1/length(myData_black$re78) * sum((myData_black$re78 * myData_black$treat)/myData_black$p_score)
term_2 <- 1/length(myData_black$re78) * sum(myData_black$treat/myData_black$p_score)

term_3 <-  1/length(myData_black$re78) * sum((myData_black$re78*(1 - myData_black$treat))/ (1 - myData_black$p_score))
term_4 <- 1/length(myData_black$re78) * sum((1-myData_black$treat)/(1-myData_black$p_score))

tau_hat_spiw_black <- term_1/term_2 - term_3/term_4 ; rm(term_1, term_2, term_3, term_4)



```
I find that $\hat \tau_{HC_{black-trim}}$ is `r round(tau_hat_HC_black,2)` and  $\hat \tau_{SPIW_{black-trim}}$ is `r round(tau_hat_spiw_black,2)`.


**IPW and SPIW for non-Black people**
```{r}
# Black 
myData_non <- myData_3 %>%
  filter(black == 0)

#HC 
tau_hat_HC_non <- 1/length(myData_non$re78) * sum(myData_non$re78 * myData_non$treat/myData_non$p_score - myData_non$re78*(1 - myData_non$treat)/ (1 - myData_non$p_score))

#SPIW
term_1 <- 1/length(myData_non$re78) * sum((myData_non$re78 * myData_non$treat)/myData_non$p_score)
term_2 <- 1/length(myData_non$re78) * sum(myData_non$treat/myData_non$p_score)

term_3 <-  1/length(myData_non$re78) * sum((myData_non$re78*(1 - myData_non$treat))/ (1 - myData_non$p_score))
term_4 <- 1/length(myData_non$re78) * sum((1-myData_non$treat)/(1-myData_non$p_score))

tau_hat_spiw_non <- term_1/term_2 - term_3/term_4 ; rm(term_1, term_2, term_3, term_4)



```
I find that $\hat \tau_{HC_{non-trim}}$ is `r round(tau_hat_HC_non,2)` and  $\hat \tau_{SPIW_{non-trim}}$ is `r round(tau_hat_spiw_non,2)`.

**ATE for Black and non-Black people in full sample**
```{r}
myBlack_full <- myData_2 %>%
  filter(black == 1)

myNon_full <- myData_2 %>%
  filter(black == 0)

ate_black <- calcATE(myBlack_full)
ate_non <- calcATE(myNon_full)




```


I DON'T THINK THIS IS RIGHT !!!!!! MY CALC ATE MAY BE WRONG 
